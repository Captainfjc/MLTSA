{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Tensorflow training 1D potential example\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Since this is a bit more advanced than the sklearn we recommend you start the other one first",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\"\"\"First we import our dataset examples\"\"\"\nfrom OneD_pot_data import potentials\nfrom OneD_pot_data import dataset\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n#This sets the potentials, don\u0027t re-run\ntotal_n_pots \u003d 25\nn_DW \u003d 5\nrelevant_DW_n \u003d 2\n#After defining the desired parameters we define the potentials accordingly\npots \u003d potentials(total_n_pots, n_DW, relevant_DW_n)\n# This creates the first dataset of data.\n# It creates the mixing coefficients don\u0027t re-run\nn_features \u003d 180\ndegree_of_mixing \u003d 2\n#We specified the number of features wanted and how much they will mix\noneD_dataset \u003d dataset(pots, n_features, degree_of_mixing)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "This has set up our dataset for further use, since TensorFlow is more scalable and compatible with GPU calculations, we will do a more extensive search on this example. \n\nLet\u0027s generate the actual linear mixed data we will use for training.   \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "#Generate the trajectories\nn_simulations \u003d 100\nn_steps \u003d 500\ndata, ans \u003d oneD_dataset.generate_linear(n_simulations, n_steps)\ndata_val, ans_val \u003d oneD_dataset.generate_linear(n_simulations/2, n_steps)\n\n#Prepare it for training\ntime_frame \u003d [30, 60] #Same time frame as the sklearn one\nX, Y \u003d oneD_dataset.PrepareData(data, ans, time_frame, mode\u003d\"Normal\")\nX_val, Y_val \u003d oneD_dataset.PrepareData(data_val, ans_val, time_frame, mode\u003d\"Normal\")",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\nNow that we have got the X and Y ready to fit to, we will train the model, in this example we want to train a Multi-Layer Perceptron just like the one in Sklearn, but we will use TensorFlow instead.\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "#Luckily we have an MLP set up to use\nfrom MLTSA_tensorflow import MLP_tf\nfrom sklearn.model_selection import train_test_split\n\n#Let\u0027s do the splits to validate our training\n# data \u003d [x_train, x_test, y_train, y_test]\nepoch_data \u003d train_test_split(X, Y, test_size\u003d0.4, stratify\u003dY) # We\u0027ll train on 40% of the data\n\nacc_train, acc_test, acc_val, loss \u003d MLP_tf.tf_train(data\u003depoch_data, validation\u003d[X_val, Y_val], mode\u003d\"notebook\")",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\nThe previous training has generated a record of the training, test and validation accuracy as well as the evolution of the loss throughout the epochs. \n\nThese can be plotted to see how the model is learning the outcome. Additionally, a checkpoint of our trained model has been created and saved for us at \"model_best_accuracy.ckpt\"\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "fig, ax \u003d plt.subplots(1,2)\nax[0].plot(acc_train*100, color\u003d\"r\", label\u003d\"Train\")\nax[0].plot(acc_test*100, color\u003d\"b\", label\u003d\"Test\")\nax[0].plot(acc_val*100, color\u003d\"g\", label\u003d\"Validation\")\nax[0].legend()\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\nax[1].plot(loss, label\u003d\"training loss\")\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"loss\")\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Now we can move onto trying the MLTSA for this ML model. For that we call the MLTSA() method within the tensorflow package.\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": " \n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}