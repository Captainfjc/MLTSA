{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Tensorflow training 1D potential example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Since this is a bit more advanced than the sklearn we recommend you start the other one first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defining Potentials: 100%|###########################################################| 25/25 [00:00<00:00, 1783.84it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"First we import our dataset examples\"\"\"\n",
    "from MLTSA_datasets.OneD_pot.OneD_pot_data import potentials\n",
    "from MLTSA_datasets.OneD_pot.OneD_pot_data import dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#This sets the potentials, don't re-run\n",
    "total_n_pots = 25\n",
    "n_DW = 5\n",
    "relevant_DW_n = 2\n",
    "#After defining the desired parameters we define the potentials accordingly\n",
    "pots = potentials(total_n_pots, n_DW, relevant_DW_n)\n",
    "# This creates the first dataset of data.\n",
    "# It creates the mixing coefficients don't re-run\n",
    "n_features = 180\n",
    "degree_of_mixing = 2\n",
    "#We specified the number of features wanted and how much they will mix\n",
    "oneD_dataset = dataset(pots, n_features, degree_of_mixing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "This has set up our dataset for further use, since TensorFlow is more scalable and compatible with GPU calculations, we will do a more extensive search on this example. \n",
    "\n",
    "Let's generate the actual linear mixed data we will use for training.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Simulations: 100%|###########################################################| 100/100 [00:23<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting simulation labels for the generated data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Simulation Outcomes: 100%|#######################################################| 100/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Simulations: 100%|#############################################################| 50/50 [00:10<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting simulation labels for the generated data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Simulation Outcomes: 100%|#########################################################| 50/50 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#Generate the trajectories\n",
    "n_simulations = 100\n",
    "n_steps = 500\n",
    "data, ans = oneD_dataset.generate_linear(n_simulations, n_steps)\n",
    "data_val, ans_val = oneD_dataset.generate_linear(int(n_simulations/2), n_steps)\n",
    "\n",
    "#Prepare it for training\n",
    "time_frame = [30, 60] #Same time frame as the sklearn one\n",
    "X, Y = oneD_dataset.PrepareData(data, ans, time_frame, mode=\"Normal\")\n",
    "X_val, Y_val = oneD_dataset.PrepareData(data_val, ans_val, time_frame, mode=\"Normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this data is generated as (X/Features, Y/labels) but those labels are strings which TensorFlow cannot handle as easy. Let's encode them for our Neural Network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#We will convert IN and OUT to numerical labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(Y.reshape(len(Y), 1)).toarray()\n",
    "Y_val = encoder.fit_transform(Y_val.reshape(len(Y_val),1)).toarray()\n",
    "print(Y)\n",
    "print(Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "Now that we have got the X and Y ready to fit to, we will train the model, in this example we want to train a Multi-Layer Perceptron just like the one in Sklearn, but we will use TensorFlow instead. For this we will have to build the models first using the build_MLP function under the MLTSA_tensorflow integrated package. This will print a summay of our model to check that the dimensions and size for each layer are correct. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Simple MLP\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 100)               18100     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,402\n",
      "Trainable params: 28,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#We will start with the basic Multi-Layer Perceptron\n",
    "from MLTSA_tensorflow import TF_2_MLP\n",
    "\n",
    "MLP = TF_2_MLP.build_MLP(n_steps, n_features, n_labels=2).model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put to train the MLP, in this case we can make use of the fit() function of our model and call the data (X,Y) directly without any other preparation. We will use X_val and Y_val later for further validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.7589 - accuracy: 0.4921 - val_loss: 0.8553 - val_accuracy: 0.3500\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7022 - accuracy: 0.5592 - val_loss: 0.7021 - val_accuracy: 0.3500\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6946 - accuracy: 0.5275 - val_loss: 0.7372 - val_accuracy: 0.3500\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5642 - val_loss: 0.7848 - val_accuracy: 0.3500\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5704 - val_loss: 0.7306 - val_accuracy: 0.3500\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6879 - accuracy: 0.5512 - val_loss: 0.7440 - val_accuracy: 0.3500\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5796 - val_loss: 0.7592 - val_accuracy: 0.3500\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6820 - accuracy: 0.5775 - val_loss: 0.7590 - val_accuracy: 0.3500\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6801 - accuracy: 0.5763 - val_loss: 0.7459 - val_accuracy: 0.3500\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6839 - accuracy: 0.5633 - val_loss: 0.7498 - val_accuracy: 0.3500\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6809 - accuracy: 0.5758 - val_loss: 0.7717 - val_accuracy: 0.3500\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6838 - accuracy: 0.5708 - val_loss: 0.7508 - val_accuracy: 0.3500\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.5688 - val_loss: 0.7473 - val_accuracy: 0.3500\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6846 - accuracy: 0.5658 - val_loss: 0.7499 - val_accuracy: 0.3500\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6812 - accuracy: 0.5742 - val_loss: 0.7532 - val_accuracy: 0.3500\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6801 - accuracy: 0.5738 - val_loss: 0.7415 - val_accuracy: 0.3500\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5742 - val_loss: 0.7516 - val_accuracy: 0.3500\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5738 - val_loss: 0.7332 - val_accuracy: 0.3500\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6795 - accuracy: 0.5796 - val_loss: 0.7586 - val_accuracy: 0.3500\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6802 - accuracy: 0.5742 - val_loss: 0.7464 - val_accuracy: 0.3500\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6790 - accuracy: 0.5758 - val_loss: 0.7332 - val_accuracy: 0.3500\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6797 - accuracy: 0.5754 - val_loss: 0.7654 - val_accuracy: 0.3500\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6800 - accuracy: 0.5758 - val_loss: 0.7302 - val_accuracy: 0.3500\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6790 - accuracy: 0.5763 - val_loss: 0.7512 - val_accuracy: 0.3500\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6776 - accuracy: 0.5763 - val_loss: 0.7384 - val_accuracy: 0.3500\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6752 - accuracy: 0.5792 - val_loss: 0.7504 - val_accuracy: 0.3500\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6768 - accuracy: 0.5754 - val_loss: 0.7335 - val_accuracy: 0.3500\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6758 - accuracy: 0.5842 - val_loss: 0.7543 - val_accuracy: 0.3500\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6791 - accuracy: 0.5733 - val_loss: 0.7312 - val_accuracy: 0.3500\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6748 - accuracy: 0.5804 - val_loss: 0.7500 - val_accuracy: 0.3500\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6741 - accuracy: 0.5771 - val_loss: 0.7303 - val_accuracy: 0.3500\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6731 - accuracy: 0.5775 - val_loss: 0.7540 - val_accuracy: 0.3500\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6707 - accuracy: 0.5771 - val_loss: 0.7259 - val_accuracy: 0.3500\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6680 - accuracy: 0.5788 - val_loss: 0.7084 - val_accuracy: 0.3500\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6685 - accuracy: 0.6000 - val_loss: 0.7949 - val_accuracy: 0.3500\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6698 - accuracy: 0.5925 - val_loss: 0.7444 - val_accuracy: 0.3500\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6672 - accuracy: 0.5962 - val_loss: 0.7645 - val_accuracy: 0.3500\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6743 - accuracy: 0.5788 - val_loss: 0.6727 - val_accuracy: 0.8067\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6700 - accuracy: 0.5933 - val_loss: 0.7351 - val_accuracy: 0.3500\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6606 - accuracy: 0.6288 - val_loss: 0.7692 - val_accuracy: 0.3500\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6591 - accuracy: 0.5854 - val_loss: 0.7110 - val_accuracy: 0.3500\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6579 - accuracy: 0.5896 - val_loss: 0.7523 - val_accuracy: 0.3500\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6563 - accuracy: 0.6017 - val_loss: 0.7023 - val_accuracy: 0.3500\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6575 - accuracy: 0.6108 - val_loss: 0.6833 - val_accuracy: 0.4217\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6539 - accuracy: 0.6083 - val_loss: 0.6725 - val_accuracy: 0.6900\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6557 - accuracy: 0.6221 - val_loss: 0.7275 - val_accuracy: 0.3500\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6457 - accuracy: 0.6358 - val_loss: 0.7564 - val_accuracy: 0.3500\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6447 - accuracy: 0.6371 - val_loss: 0.7618 - val_accuracy: 0.3500\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6416 - accuracy: 0.6333 - val_loss: 0.7544 - val_accuracy: 0.3500\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6433 - accuracy: 0.6358 - val_loss: 0.7383 - val_accuracy: 0.3500\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6383 - accuracy: 0.6513 - val_loss: 0.7198 - val_accuracy: 0.3500\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6272 - accuracy: 0.6675 - val_loss: 0.7300 - val_accuracy: 0.3500\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6267 - accuracy: 0.6592 - val_loss: 0.7106 - val_accuracy: 0.3567\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6360 - accuracy: 0.6392 - val_loss: 0.6856 - val_accuracy: 0.3983\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6338 - accuracy: 0.6342 - val_loss: 0.6508 - val_accuracy: 0.7050\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6208 - accuracy: 0.6750 - val_loss: 0.6381 - val_accuracy: 0.8383\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6168 - accuracy: 0.7108 - val_loss: 0.6374 - val_accuracy: 0.8117\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6083 - accuracy: 0.7117 - val_loss: 0.7189 - val_accuracy: 0.3567\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6026 - accuracy: 0.6850 - val_loss: 0.6442 - val_accuracy: 0.6717\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6058 - accuracy: 0.6900 - val_loss: 0.6841 - val_accuracy: 0.4050\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6148 - accuracy: 0.6229 - val_loss: 0.8068 - val_accuracy: 0.3500\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6113 - accuracy: 0.6729 - val_loss: 0.8108 - val_accuracy: 0.3500\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5998 - accuracy: 0.6717 - val_loss: 0.8004 - val_accuracy: 0.3500\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5986 - accuracy: 0.6888 - val_loss: 0.7716 - val_accuracy: 0.3533\n",
      "Epoch 65/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5841 - accuracy: 0.7242 - val_loss: 0.6424 - val_accuracy: 0.6267\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5701 - accuracy: 0.7625 - val_loss: 0.6236 - val_accuracy: 0.6950\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5640 - accuracy: 0.7817 - val_loss: 0.6215 - val_accuracy: 0.6900\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5717 - accuracy: 0.7638 - val_loss: 0.7642 - val_accuracy: 0.3600\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5606 - accuracy: 0.7367 - val_loss: 0.6253 - val_accuracy: 0.6450\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5484 - accuracy: 0.8046 - val_loss: 0.6932 - val_accuracy: 0.4133\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5454 - accuracy: 0.7425 - val_loss: 0.5775 - val_accuracy: 0.8150\n",
      "Epoch 72/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5479 - accuracy: 0.7833 - val_loss: 0.7279 - val_accuracy: 0.3950\n",
      "Epoch 73/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5720 - accuracy: 0.6596 - val_loss: 0.5671 - val_accuracy: 0.8117\n",
      "Epoch 74/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5660 - accuracy: 0.6792 - val_loss: 0.6046 - val_accuracy: 0.6633\n",
      "Epoch 75/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5261 - accuracy: 0.7867 - val_loss: 0.7090 - val_accuracy: 0.4083\n",
      "Epoch 76/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5265 - accuracy: 0.7529 - val_loss: 0.5274 - val_accuracy: 0.7417\n",
      "Epoch 77/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5435 - accuracy: 0.7271 - val_loss: 0.6388 - val_accuracy: 0.5367\n",
      "Epoch 78/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5152 - accuracy: 0.7617 - val_loss: 0.7461 - val_accuracy: 0.3950\n",
      "Epoch 79/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5109 - accuracy: 0.7696 - val_loss: 0.5371 - val_accuracy: 0.8400\n",
      "Epoch 80/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5198 - accuracy: 0.7646 - val_loss: 0.6589 - val_accuracy: 0.4833\n",
      "Epoch 81/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4985 - accuracy: 0.7875 - val_loss: 0.7670 - val_accuracy: 0.3950\n",
      "Epoch 82/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5360 - accuracy: 0.7163 - val_loss: 0.5043 - val_accuracy: 0.8083\n",
      "Epoch 83/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5029 - accuracy: 0.7771 - val_loss: 0.7213 - val_accuracy: 0.4267\n",
      "Epoch 84/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5083 - accuracy: 0.7271 - val_loss: 0.6708 - val_accuracy: 0.4733\n",
      "Epoch 85/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4915 - accuracy: 0.7621 - val_loss: 0.4961 - val_accuracy: 0.8600\n",
      "Epoch 86/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4864 - accuracy: 0.7950 - val_loss: 0.5570 - val_accuracy: 0.7450\n",
      "Epoch 87/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4740 - accuracy: 0.8017 - val_loss: 0.6576 - val_accuracy: 0.4983\n",
      "Epoch 88/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4649 - accuracy: 0.8125 - val_loss: 0.4889 - val_accuracy: 0.8717\n",
      "Epoch 89/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4709 - accuracy: 0.7883 - val_loss: 0.6554 - val_accuracy: 0.5117\n",
      "Epoch 90/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4580 - accuracy: 0.8029 - val_loss: 0.5185 - val_accuracy: 0.7900\n",
      "Epoch 91/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4403 - accuracy: 0.8567 - val_loss: 0.5841 - val_accuracy: 0.6483\n",
      "Epoch 92/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4407 - accuracy: 0.8392 - val_loss: 0.5037 - val_accuracy: 0.8083\n",
      "Epoch 93/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4298 - accuracy: 0.8592 - val_loss: 0.6179 - val_accuracy: 0.5983\n",
      "Epoch 94/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4228 - accuracy: 0.8413 - val_loss: 0.4827 - val_accuracy: 0.8100\n",
      "Epoch 95/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4353 - accuracy: 0.8250 - val_loss: 0.4730 - val_accuracy: 0.8217\n",
      "Epoch 96/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4220 - accuracy: 0.8367 - val_loss: 0.6675 - val_accuracy: 0.5200\n",
      "Epoch 97/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4160 - accuracy: 0.8392 - val_loss: 0.5727 - val_accuracy: 0.6483\n",
      "Epoch 98/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3993 - accuracy: 0.8617 - val_loss: 0.4912 - val_accuracy: 0.7883\n",
      "Epoch 99/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4016 - accuracy: 0.8429 - val_loss: 0.4446 - val_accuracy: 0.8700\n",
      "Epoch 100/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4132 - accuracy: 0.8171 - val_loss: 0.4703 - val_accuracy: 0.8050\n",
      "Epoch 101/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3940 - accuracy: 0.8571 - val_loss: 0.4464 - val_accuracy: 0.8433\n",
      "Epoch 102/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4335 - accuracy: 0.7971 - val_loss: 0.5014 - val_accuracy: 0.7667\n",
      "Epoch 103/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3719 - accuracy: 0.8767 - val_loss: 0.5303 - val_accuracy: 0.7033\n",
      "Epoch 104/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4080 - accuracy: 0.8242 - val_loss: 0.7028 - val_accuracy: 0.5100\n",
      "Epoch 105/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4390 - accuracy: 0.7633 - val_loss: 0.5535 - val_accuracy: 0.6667\n",
      "Epoch 106/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3685 - accuracy: 0.8600 - val_loss: 0.4375 - val_accuracy: 0.8117\n",
      "Epoch 107/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3995 - accuracy: 0.8371 - val_loss: 0.8412 - val_accuracy: 0.4433\n",
      "Epoch 108/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4199 - accuracy: 0.8029 - val_loss: 0.5556 - val_accuracy: 0.6633\n",
      "Epoch 109/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3808 - accuracy: 0.8363 - val_loss: 0.4210 - val_accuracy: 0.8733\n",
      "Epoch 110/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4040 - accuracy: 0.8225 - val_loss: 0.4284 - val_accuracy: 0.8300\n",
      "Epoch 111/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3900 - accuracy: 0.8329 - val_loss: 0.7343 - val_accuracy: 0.5067\n",
      "Epoch 112/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3899 - accuracy: 0.8213 - val_loss: 0.4154 - val_accuracy: 0.8550\n",
      "Epoch 113/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3649 - accuracy: 0.8554 - val_loss: 0.4561 - val_accuracy: 0.7917\n",
      "Epoch 114/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3492 - accuracy: 0.8733 - val_loss: 0.6123 - val_accuracy: 0.6433\n",
      "Epoch 115/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3745 - accuracy: 0.8388 - val_loss: 0.4113 - val_accuracy: 0.8567\n",
      "Epoch 116/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3504 - accuracy: 0.8637 - val_loss: 0.5035 - val_accuracy: 0.7433\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3629 - accuracy: 0.8550 - val_loss: 0.7332 - val_accuracy: 0.5183\n",
      "Epoch 118/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3632 - accuracy: 0.8433 - val_loss: 0.4246 - val_accuracy: 0.8083\n",
      "Epoch 119/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3466 - accuracy: 0.8658 - val_loss: 0.4574 - val_accuracy: 0.7783\n",
      "Epoch 120/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3209 - accuracy: 0.8933 - val_loss: 0.4348 - val_accuracy: 0.8117\n",
      "Epoch 121/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3437 - accuracy: 0.8633 - val_loss: 0.4386 - val_accuracy: 0.8033\n",
      "Epoch 122/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4216 - accuracy: 0.7979 - val_loss: 0.5593 - val_accuracy: 0.6650\n",
      "Epoch 123/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3302 - accuracy: 0.8696 - val_loss: 0.3989 - val_accuracy: 0.8750\n",
      "Epoch 124/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3745 - accuracy: 0.8196 - val_loss: 0.4331 - val_accuracy: 0.8067\n",
      "Epoch 125/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3731 - accuracy: 0.8250 - val_loss: 0.7168 - val_accuracy: 0.5433\n",
      "Epoch 126/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3923 - accuracy: 0.8008 - val_loss: 0.4092 - val_accuracy: 0.8200\n",
      "Epoch 127/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3433 - accuracy: 0.8667 - val_loss: 0.4623 - val_accuracy: 0.7750\n",
      "Epoch 128/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3369 - accuracy: 0.8575 - val_loss: 0.4008 - val_accuracy: 0.8317\n",
      "Epoch 129/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3191 - accuracy: 0.8867 - val_loss: 0.4570 - val_accuracy: 0.7767\n",
      "Epoch 130/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3047 - accuracy: 0.8917 - val_loss: 0.4182 - val_accuracy: 0.8083\n",
      "Epoch 131/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3115 - accuracy: 0.8921 - val_loss: 0.4815 - val_accuracy: 0.7600\n",
      "Epoch 132/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3022 - accuracy: 0.8925 - val_loss: 0.4413 - val_accuracy: 0.7883\n",
      "Epoch 133/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2921 - accuracy: 0.9038 - val_loss: 0.5442 - val_accuracy: 0.6833\n",
      "Epoch 134/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2947 - accuracy: 0.8958 - val_loss: 0.4192 - val_accuracy: 0.8117\n",
      "Epoch 135/500\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2490 - accuracy: 0.93 - 0s 11ms/step - loss: 0.2835 - accuracy: 0.9100 - val_loss: 0.5316 - val_accuracy: 0.6917\n",
      "Epoch 136/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3172 - accuracy: 0.8712 - val_loss: 0.4367 - val_accuracy: 0.7900\n",
      "Epoch 137/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3092 - accuracy: 0.8792 - val_loss: 0.3974 - val_accuracy: 0.8017\n",
      "Epoch 138/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2926 - accuracy: 0.8892 - val_loss: 0.4020 - val_accuracy: 0.8083\n",
      "Epoch 139/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2812 - accuracy: 0.9008 - val_loss: 0.3922 - val_accuracy: 0.8017\n",
      "Epoch 140/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2850 - accuracy: 0.8888 - val_loss: 0.3865 - val_accuracy: 0.8350\n",
      "Epoch 141/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3267 - accuracy: 0.8429 - val_loss: 0.4069 - val_accuracy: 0.8667\n",
      "Epoch 142/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3864 - accuracy: 0.8012 - val_loss: 0.3980 - val_accuracy: 0.8067\n",
      "Epoch 143/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3218 - accuracy: 0.8592 - val_loss: 0.5060 - val_accuracy: 0.7333\n",
      "Epoch 144/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2850 - accuracy: 0.8871 - val_loss: 0.4228 - val_accuracy: 0.8433\n",
      "Epoch 145/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3865 - accuracy: 0.8012 - val_loss: 0.4126 - val_accuracy: 0.7983\n",
      "Epoch 146/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4268 - accuracy: 0.7688 - val_loss: 0.5473 - val_accuracy: 0.6867\n",
      "Epoch 147/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3890 - accuracy: 0.8029 - val_loss: 0.4119 - val_accuracy: 0.8100\n",
      "Epoch 148/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4069 - accuracy: 0.7908 - val_loss: 0.4472 - val_accuracy: 0.7733\n",
      "Epoch 149/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3444 - accuracy: 0.8413 - val_loss: 0.5884 - val_accuracy: 0.6633\n",
      "Epoch 150/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3220 - accuracy: 0.8554 - val_loss: 0.3886 - val_accuracy: 0.8083\n",
      "Epoch 151/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3025 - accuracy: 0.8808 - val_loss: 0.5076 - val_accuracy: 0.7400\n",
      "Epoch 152/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2932 - accuracy: 0.8783 - val_loss: 0.4141 - val_accuracy: 0.8100\n",
      "Epoch 153/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2616 - accuracy: 0.9092 - val_loss: 0.4259 - val_accuracy: 0.7967\n",
      "Epoch 154/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2814 - accuracy: 0.8892 - val_loss: 0.5052 - val_accuracy: 0.7383\n",
      "Epoch 155/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2836 - accuracy: 0.8846 - val_loss: 0.3799 - val_accuracy: 0.8417\n",
      "Epoch 156/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2891 - accuracy: 0.8833 - val_loss: 0.4934 - val_accuracy: 0.7450\n",
      "Epoch 157/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2665 - accuracy: 0.9021 - val_loss: 0.4375 - val_accuracy: 0.7833\n",
      "Epoch 158/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2652 - accuracy: 0.8979 - val_loss: 0.4063 - val_accuracy: 0.8117\n",
      "Epoch 159/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2659 - accuracy: 0.9050 - val_loss: 0.4304 - val_accuracy: 0.7917\n",
      "Epoch 160/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2656 - accuracy: 0.8950 - val_loss: 0.3945 - val_accuracy: 0.8050\n",
      "Epoch 161/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2547 - accuracy: 0.9062 - val_loss: 0.3790 - val_accuracy: 0.8300\n",
      "Epoch 162/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2743 - accuracy: 0.8967 - val_loss: 0.4569 - val_accuracy: 0.7650\n",
      "Epoch 163/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2774 - accuracy: 0.8879 - val_loss: 0.6304 - val_accuracy: 0.6567\n",
      "Epoch 164/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2648 - accuracy: 0.8971 - val_loss: 0.4987 - val_accuracy: 0.7450\n",
      "Epoch 165/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2596 - accuracy: 0.9058 - val_loss: 0.4944 - val_accuracy: 0.7450\n",
      "Epoch 166/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2530 - accuracy: 0.9104 - val_loss: 0.4489 - val_accuracy: 0.7717\n",
      "Epoch 167/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2461 - accuracy: 0.9129 - val_loss: 0.4230 - val_accuracy: 0.7967\n",
      "Epoch 168/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2498 - accuracy: 0.9087 - val_loss: 0.3748 - val_accuracy: 0.8183\n",
      "Epoch 169/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2489 - accuracy: 0.9075 - val_loss: 0.6011 - val_accuracy: 0.6683\n",
      "Epoch 170/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2803 - accuracy: 0.8717 - val_loss: 0.4425 - val_accuracy: 0.8317\n",
      "Epoch 171/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3616 - accuracy: 0.8150 - val_loss: 0.5827 - val_accuracy: 0.6750\n",
      "Epoch 172/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4019 - accuracy: 0.7875 - val_loss: 0.4686 - val_accuracy: 0.7667\n",
      "Epoch 173/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3408 - accuracy: 0.8367 - val_loss: 0.4409 - val_accuracy: 0.7817\n",
      "Epoch 174/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4223 - accuracy: 0.7825 - val_loss: 0.4756 - val_accuracy: 0.7567\n",
      "Epoch 175/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3319 - accuracy: 0.8462 - val_loss: 0.4143 - val_accuracy: 0.8033\n",
      "Epoch 176/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2667 - accuracy: 0.8925 - val_loss: 0.4681 - val_accuracy: 0.7583\n",
      "Epoch 177/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2540 - accuracy: 0.9008 - val_loss: 0.3690 - val_accuracy: 0.8150\n",
      "Epoch 178/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2617 - accuracy: 0.8975 - val_loss: 0.4441 - val_accuracy: 0.7750\n",
      "Epoch 179/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2382 - accuracy: 0.9117 - val_loss: 0.4020 - val_accuracy: 0.8167\n",
      "Epoch 180/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2428 - accuracy: 0.9087 - val_loss: 0.5112 - val_accuracy: 0.7433\n",
      "Epoch 181/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2847 - accuracy: 0.8763 - val_loss: 0.4683 - val_accuracy: 0.7583\n",
      "Epoch 182/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2813 - accuracy: 0.8750 - val_loss: 0.3716 - val_accuracy: 0.8567\n",
      "Epoch 183/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2663 - accuracy: 0.8979 - val_loss: 0.5490 - val_accuracy: 0.7000\n",
      "Epoch 184/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2897 - accuracy: 0.8658 - val_loss: 0.3745 - val_accuracy: 0.8633\n",
      "Epoch 185/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2644 - accuracy: 0.8879 - val_loss: 0.6440 - val_accuracy: 0.6650\n",
      "Epoch 186/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2777 - accuracy: 0.8783 - val_loss: 0.3612 - val_accuracy: 0.8467\n",
      "Epoch 187/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2767 - accuracy: 0.8754 - val_loss: 0.4657 - val_accuracy: 0.7600\n",
      "Epoch 188/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2759 - accuracy: 0.8783 - val_loss: 0.6342 - val_accuracy: 0.6683\n",
      "Epoch 189/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2920 - accuracy: 0.8679 - val_loss: 0.3675 - val_accuracy: 0.8583\n",
      "Epoch 190/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2702 - accuracy: 0.8821 - val_loss: 0.4961 - val_accuracy: 0.7450\n",
      "Epoch 191/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2533 - accuracy: 0.8942 - val_loss: 0.3690 - val_accuracy: 0.8217\n",
      "Epoch 192/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2738 - accuracy: 0.8779 - val_loss: 0.4462 - val_accuracy: 0.7733\n",
      "Epoch 193/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2794 - accuracy: 0.8737 - val_loss: 0.4268 - val_accuracy: 0.8000\n",
      "Epoch 194/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2430 - accuracy: 0.9054 - val_loss: 0.3662 - val_accuracy: 0.8233\n",
      "Epoch 195/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2309 - accuracy: 0.9158 - val_loss: 0.4518 - val_accuracy: 0.7700\n",
      "Epoch 196/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2232 - accuracy: 0.9175 - val_loss: 0.4238 - val_accuracy: 0.8000\n",
      "Epoch 197/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2258 - accuracy: 0.9137 - val_loss: 0.4117 - val_accuracy: 0.8133\n",
      "Epoch 198/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2271 - accuracy: 0.9137 - val_loss: 0.3984 - val_accuracy: 0.8167\n",
      "Epoch 199/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2221 - accuracy: 0.9162 - val_loss: 0.4401 - val_accuracy: 0.7817\n",
      "Epoch 200/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2274 - accuracy: 0.9208 - val_loss: 0.4055 - val_accuracy: 0.8150\n",
      "Epoch 201/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2210 - accuracy: 0.9162 - val_loss: 0.3825 - val_accuracy: 0.8083\n",
      "Epoch 202/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2219 - accuracy: 0.9150 - val_loss: 0.4406 - val_accuracy: 0.7867\n",
      "Epoch 203/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2210 - accuracy: 0.9100 - val_loss: 0.4269 - val_accuracy: 0.8000\n",
      "Epoch 204/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2241 - accuracy: 0.9125 - val_loss: 0.4613 - val_accuracy: 0.7633\n",
      "Epoch 205/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2256 - accuracy: 0.9083 - val_loss: 0.3638 - val_accuracy: 0.8517\n",
      "Epoch 206/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2458 - accuracy: 0.8913 - val_loss: 0.3642 - val_accuracy: 0.8417\n",
      "Epoch 207/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2432 - accuracy: 0.8979 - val_loss: 0.5345 - val_accuracy: 0.7400\n",
      "Epoch 208/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2138 - accuracy: 0.9158 - val_loss: 0.3810 - val_accuracy: 0.8100\n",
      "Epoch 209/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2153 - accuracy: 0.9204 - val_loss: 0.3753 - val_accuracy: 0.8017\n",
      "Epoch 210/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2154 - accuracy: 0.9175 - val_loss: 0.7129 - val_accuracy: 0.6600\n",
      "Epoch 211/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2507 - accuracy: 0.8929 - val_loss: 0.3668 - val_accuracy: 0.8217\n",
      "Epoch 212/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2135 - accuracy: 0.9183 - val_loss: 0.4160 - val_accuracy: 0.8133\n",
      "Epoch 213/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2672 - accuracy: 0.8708 - val_loss: 0.9767 - val_accuracy: 0.5417\n",
      "Epoch 214/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3548 - accuracy: 0.8238 - val_loss: 0.3902 - val_accuracy: 0.8717\n",
      "Epoch 215/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2979 - accuracy: 0.8571 - val_loss: 0.4772 - val_accuracy: 0.7517\n",
      "Epoch 216/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2612 - accuracy: 0.8858 - val_loss: 0.4409 - val_accuracy: 0.7717\n",
      "Epoch 217/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2139 - accuracy: 0.9183 - val_loss: 0.3824 - val_accuracy: 0.8233\n",
      "Epoch 218/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2112 - accuracy: 0.9233 - val_loss: 0.4186 - val_accuracy: 0.7967\n",
      "Epoch 219/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2442 - accuracy: 0.9017 - val_loss: 0.3620 - val_accuracy: 0.8133\n",
      "Epoch 220/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2763 - accuracy: 0.8808 - val_loss: 0.3502 - val_accuracy: 0.8450\n",
      "Epoch 221/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2822 - accuracy: 0.8737 - val_loss: 0.3651 - val_accuracy: 0.8583\n",
      "Epoch 222/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2498 - accuracy: 0.8975 - val_loss: 0.5849 - val_accuracy: 0.6833\n",
      "Epoch 223/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2913 - accuracy: 0.8675 - val_loss: 0.3981 - val_accuracy: 0.8717\n",
      "Epoch 224/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3248 - accuracy: 0.8450 - val_loss: 0.5004 - val_accuracy: 0.7533\n",
      "Epoch 225/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2887 - accuracy: 0.8637 - val_loss: 0.5658 - val_accuracy: 0.6983\n",
      "Epoch 226/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2779 - accuracy: 0.8696 - val_loss: 0.3793 - val_accuracy: 0.8700\n",
      "Epoch 227/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2689 - accuracy: 0.8754 - val_loss: 0.6515 - val_accuracy: 0.6750\n",
      "Epoch 228/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2773 - accuracy: 0.8704 - val_loss: 0.5658 - val_accuracy: 0.6950\n",
      "Epoch 229/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2433 - accuracy: 0.8958 - val_loss: 0.3492 - val_accuracy: 0.8550\n",
      "Epoch 230/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2475 - accuracy: 0.8958 - val_loss: 0.4416 - val_accuracy: 0.7800\n",
      "Epoch 231/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2259 - accuracy: 0.9104 - val_loss: 0.4040 - val_accuracy: 0.8167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2435 - accuracy: 0.8954 - val_loss: 0.3566 - val_accuracy: 0.8433\n",
      "Epoch 233/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2335 - accuracy: 0.9004 - val_loss: 0.4826 - val_accuracy: 0.7517\n",
      "Epoch 234/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2957 - accuracy: 0.8600 - val_loss: 0.5236 - val_accuracy: 0.7617\n",
      "Epoch 235/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4152 - accuracy: 0.7967 - val_loss: 0.5771 - val_accuracy: 0.6917\n",
      "Epoch 236/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2955 - accuracy: 0.8733 - val_loss: 0.3675 - val_accuracy: 0.8200\n",
      "Epoch 237/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2861 - accuracy: 0.8708 - val_loss: 0.4944 - val_accuracy: 0.7333\n",
      "Epoch 238/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2634 - accuracy: 0.8929 - val_loss: 0.3713 - val_accuracy: 0.8133\n",
      "Epoch 239/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2856 - accuracy: 0.8775 - val_loss: 0.3856 - val_accuracy: 0.8017\n",
      "Epoch 240/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3186 - accuracy: 0.8479 - val_loss: 0.5386 - val_accuracy: 0.7017\n",
      "Epoch 241/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2875 - accuracy: 0.8625 - val_loss: 0.3788 - val_accuracy: 0.8667\n",
      "Epoch 242/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2855 - accuracy: 0.8746 - val_loss: 0.4709 - val_accuracy: 0.7483\n",
      "Epoch 243/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2394 - accuracy: 0.9071 - val_loss: 0.3763 - val_accuracy: 0.8067\n",
      "Epoch 244/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2498 - accuracy: 0.8983 - val_loss: 0.4011 - val_accuracy: 0.8067\n",
      "Epoch 245/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2295 - accuracy: 0.9175 - val_loss: 0.3703 - val_accuracy: 0.8117\n",
      "Epoch 246/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2279 - accuracy: 0.9183 - val_loss: 0.3668 - val_accuracy: 0.8100\n",
      "Epoch 247/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2305 - accuracy: 0.9125 - val_loss: 0.4660 - val_accuracy: 0.7500\n",
      "Epoch 248/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2341 - accuracy: 0.9104 - val_loss: 0.3573 - val_accuracy: 0.8467\n",
      "Epoch 249/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2779 - accuracy: 0.8737 - val_loss: 0.5240 - val_accuracy: 0.7233\n",
      "Epoch 250/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2440 - accuracy: 0.8996 - val_loss: 0.3611 - val_accuracy: 0.8233\n",
      "Epoch 251/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2613 - accuracy: 0.8867 - val_loss: 0.4408 - val_accuracy: 0.7767\n",
      "Epoch 252/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2342 - accuracy: 0.9067 - val_loss: 0.4540 - val_accuracy: 0.7600\n",
      "Epoch 253/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2427 - accuracy: 0.9025 - val_loss: 0.4475 - val_accuracy: 0.7750\n",
      "Epoch 254/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2278 - accuracy: 0.9083 - val_loss: 0.4042 - val_accuracy: 0.8050\n",
      "Epoch 255/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2310 - accuracy: 0.9075 - val_loss: 0.3606 - val_accuracy: 0.8450\n",
      "Epoch 256/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2421 - accuracy: 0.8942 - val_loss: 0.4535 - val_accuracy: 0.7700\n",
      "Epoch 257/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2299 - accuracy: 0.9054 - val_loss: 0.5105 - val_accuracy: 0.7350\n",
      "Epoch 258/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2392 - accuracy: 0.9042 - val_loss: 0.3805 - val_accuracy: 0.8717\n",
      "Epoch 259/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2622 - accuracy: 0.8775 - val_loss: 0.4953 - val_accuracy: 0.7567\n",
      "Epoch 260/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2482 - accuracy: 0.8825 - val_loss: 0.6310 - val_accuracy: 0.6900\n",
      "Epoch 261/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2738 - accuracy: 0.8788 - val_loss: 0.3855 - val_accuracy: 0.8700\n",
      "Epoch 262/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3283 - accuracy: 0.8421 - val_loss: 0.4188 - val_accuracy: 0.8067\n",
      "Epoch 263/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2732 - accuracy: 0.8683 - val_loss: 0.4535 - val_accuracy: 0.7750\n",
      "Epoch 264/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2857 - accuracy: 0.8721 - val_loss: 0.3617 - val_accuracy: 0.8467\n",
      "Epoch 265/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2205 - accuracy: 0.9087 - val_loss: 0.5832 - val_accuracy: 0.7100\n",
      "Epoch 266/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2556 - accuracy: 0.8879 - val_loss: 0.4033 - val_accuracy: 0.8717\n",
      "Epoch 267/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2831 - accuracy: 0.8675 - val_loss: 0.4581 - val_accuracy: 0.7683\n",
      "Epoch 268/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2186 - accuracy: 0.9075 - val_loss: 0.4836 - val_accuracy: 0.7650\n",
      "Epoch 269/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2006 - accuracy: 0.9200 - val_loss: 0.3915 - val_accuracy: 0.8217\n",
      "Epoch 270/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1887 - accuracy: 0.9300 - val_loss: 0.4771 - val_accuracy: 0.7617\n",
      "Epoch 271/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2019 - accuracy: 0.9162 - val_loss: 0.4310 - val_accuracy: 0.8000\n",
      "Epoch 272/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1935 - accuracy: 0.9275 - val_loss: 0.4156 - val_accuracy: 0.8117\n",
      "Epoch 273/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2161 - accuracy: 0.9104 - val_loss: 0.3752 - val_accuracy: 0.8667\n",
      "Epoch 274/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2780 - accuracy: 0.8737 - val_loss: 0.4392 - val_accuracy: 0.7950\n",
      "Epoch 275/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2520 - accuracy: 0.8833 - val_loss: 0.5151 - val_accuracy: 0.7533\n",
      "Epoch 276/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2401 - accuracy: 0.8929 - val_loss: 0.3612 - val_accuracy: 0.8617\n",
      "Epoch 277/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2133 - accuracy: 0.9054 - val_loss: 0.3719 - val_accuracy: 0.8100\n",
      "Epoch 278/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2281 - accuracy: 0.8950 - val_loss: 0.7455 - val_accuracy: 0.6567\n",
      "Epoch 279/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2565 - accuracy: 0.8871 - val_loss: 0.3897 - val_accuracy: 0.8667\n",
      "Epoch 280/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2432 - accuracy: 0.8883 - val_loss: 0.8480 - val_accuracy: 0.6133\n",
      "Epoch 281/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2878 - accuracy: 0.8767 - val_loss: 0.3730 - val_accuracy: 0.8700\n",
      "Epoch 282/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2458 - accuracy: 0.8875 - val_loss: 0.5761 - val_accuracy: 0.7300\n",
      "Epoch 283/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2061 - accuracy: 0.9142 - val_loss: 0.3627 - val_accuracy: 0.8067\n",
      "Epoch 284/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1886 - accuracy: 0.9292 - val_loss: 0.3753 - val_accuracy: 0.8217\n",
      "Epoch 285/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1964 - accuracy: 0.9262 - val_loss: 0.3860 - val_accuracy: 0.8017\n",
      "Epoch 286/500\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1757 - accuracy: 0.94 - 0s 11ms/step - loss: 0.2096 - accuracy: 0.9133 - val_loss: 0.4963 - val_accuracy: 0.7600\n",
      "Epoch 287/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2079 - accuracy: 0.9133 - val_loss: 0.3591 - val_accuracy: 0.8417\n",
      "Epoch 288/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1949 - accuracy: 0.9196 - val_loss: 0.6055 - val_accuracy: 0.7067\n",
      "Epoch 289/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2147 - accuracy: 0.9158 - val_loss: 0.3550 - val_accuracy: 0.8467\n",
      "Epoch 290/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2379 - accuracy: 0.8950 - val_loss: 0.4786 - val_accuracy: 0.7617\n",
      "Epoch 291/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2482 - accuracy: 0.8867 - val_loss: 0.5312 - val_accuracy: 0.7483\n",
      "Epoch 292/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2148 - accuracy: 0.9171 - val_loss: 0.3715 - val_accuracy: 0.8033\n",
      "Epoch 293/500\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1696 - accuracy: 0.94 - 0s 11ms/step - loss: 0.1775 - accuracy: 0.9333 - val_loss: 0.3727 - val_accuracy: 0.8133\n",
      "Epoch 294/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1797 - accuracy: 0.9325 - val_loss: 0.4060 - val_accuracy: 0.8167\n",
      "Epoch 295/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2032 - accuracy: 0.9125 - val_loss: 0.5725 - val_accuracy: 0.7383\n",
      "Epoch 296/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2007 - accuracy: 0.9125 - val_loss: 0.3629 - val_accuracy: 0.8167\n",
      "Epoch 297/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1953 - accuracy: 0.9233 - val_loss: 0.4445 - val_accuracy: 0.7933\n",
      "Epoch 298/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2012 - accuracy: 0.9100 - val_loss: 0.4004 - val_accuracy: 0.8700\n",
      "Epoch 299/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2758 - accuracy: 0.8625 - val_loss: 0.4423 - val_accuracy: 0.7783\n",
      "Epoch 300/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2264 - accuracy: 0.9000 - val_loss: 0.4412 - val_accuracy: 0.7800\n",
      "Epoch 301/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2677 - accuracy: 0.8796 - val_loss: 0.3654 - val_accuracy: 0.8583\n",
      "Epoch 302/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2354 - accuracy: 0.8979 - val_loss: 0.4910 - val_accuracy: 0.7683\n",
      "Epoch 303/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1983 - accuracy: 0.9154 - val_loss: 0.3951 - val_accuracy: 0.8233\n",
      "Epoch 304/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2113 - accuracy: 0.9087 - val_loss: 0.6027 - val_accuracy: 0.7117\n",
      "Epoch 305/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1988 - accuracy: 0.9200 - val_loss: 0.3567 - val_accuracy: 0.8317\n",
      "Epoch 306/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2074 - accuracy: 0.9154 - val_loss: 0.3596 - val_accuracy: 0.8200\n",
      "Epoch 307/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1783 - accuracy: 0.9325 - val_loss: 0.4008 - val_accuracy: 0.8133\n",
      "Epoch 308/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1828 - accuracy: 0.9296 - val_loss: 0.3582 - val_accuracy: 0.8300\n",
      "Epoch 309/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1888 - accuracy: 0.9262 - val_loss: 0.4606 - val_accuracy: 0.7817\n",
      "Epoch 310/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1991 - accuracy: 0.9179 - val_loss: 0.4182 - val_accuracy: 0.8183\n",
      "Epoch 311/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1905 - accuracy: 0.9187 - val_loss: 0.3672 - val_accuracy: 0.8067\n",
      "Epoch 312/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1775 - accuracy: 0.9275 - val_loss: 0.4235 - val_accuracy: 0.8167\n",
      "Epoch 313/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1756 - accuracy: 0.9329 - val_loss: 0.3785 - val_accuracy: 0.8050\n",
      "Epoch 314/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1842 - accuracy: 0.9208 - val_loss: 0.3926 - val_accuracy: 0.8217\n",
      "Epoch 315/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1757 - accuracy: 0.9312 - val_loss: 0.3544 - val_accuracy: 0.8250\n",
      "Epoch 316/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1832 - accuracy: 0.9233 - val_loss: 0.3939 - val_accuracy: 0.8183\n",
      "Epoch 317/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1750 - accuracy: 0.9283 - val_loss: 0.4220 - val_accuracy: 0.8167\n",
      "Epoch 318/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1777 - accuracy: 0.9317 - val_loss: 0.4390 - val_accuracy: 0.8033\n",
      "Epoch 319/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1737 - accuracy: 0.9283 - val_loss: 0.3682 - val_accuracy: 0.8283\n",
      "Epoch 320/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1979 - accuracy: 0.9146 - val_loss: 0.3643 - val_accuracy: 0.8217\n",
      "Epoch 321/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2068 - accuracy: 0.9096 - val_loss: 0.4749 - val_accuracy: 0.7783\n",
      "Epoch 322/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2385 - accuracy: 0.8925 - val_loss: 0.7989 - val_accuracy: 0.6683\n",
      "Epoch 323/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2997 - accuracy: 0.8667 - val_loss: 0.3814 - val_accuracy: 0.8383\n",
      "Epoch 324/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2057 - accuracy: 0.9142 - val_loss: 0.3554 - val_accuracy: 0.8400\n",
      "Epoch 325/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1938 - accuracy: 0.9179 - val_loss: 0.3824 - val_accuracy: 0.8333\n",
      "Epoch 326/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2342 - accuracy: 0.9004 - val_loss: 0.4891 - val_accuracy: 0.7817\n",
      "Epoch 327/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3142 - accuracy: 0.8512 - val_loss: 0.6251 - val_accuracy: 0.7000\n",
      "Epoch 328/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3222 - accuracy: 0.8483 - val_loss: 0.3875 - val_accuracy: 0.8633\n",
      "Epoch 329/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3056 - accuracy: 0.8587 - val_loss: 0.7583 - val_accuracy: 0.6617\n",
      "Epoch 330/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2591 - accuracy: 0.8850 - val_loss: 0.3517 - val_accuracy: 0.8700\n",
      "Epoch 331/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2615 - accuracy: 0.8796 - val_loss: 0.5178 - val_accuracy: 0.7617\n",
      "Epoch 332/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2195 - accuracy: 0.9046 - val_loss: 0.3922 - val_accuracy: 0.8033\n",
      "Epoch 333/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1762 - accuracy: 0.9296 - val_loss: 0.4626 - val_accuracy: 0.7917\n",
      "Epoch 334/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2277 - accuracy: 0.8975 - val_loss: 0.4070 - val_accuracy: 0.8067\n",
      "Epoch 335/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1847 - accuracy: 0.9212 - val_loss: 0.4833 - val_accuracy: 0.7750\n",
      "Epoch 336/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2011 - accuracy: 0.9142 - val_loss: 0.4785 - val_accuracy: 0.7767\n",
      "Epoch 337/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1900 - accuracy: 0.9225 - val_loss: 0.3717 - val_accuracy: 0.8200\n",
      "Epoch 338/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1879 - accuracy: 0.9250 - val_loss: 0.4565 - val_accuracy: 0.7983\n",
      "Epoch 339/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1844 - accuracy: 0.9246 - val_loss: 0.4971 - val_accuracy: 0.7650\n",
      "Epoch 340/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1763 - accuracy: 0.9292 - val_loss: 0.3882 - val_accuracy: 0.8183\n",
      "Epoch 341/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1877 - accuracy: 0.9225 - val_loss: 0.4831 - val_accuracy: 0.7800\n",
      "Epoch 342/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1757 - accuracy: 0.9233 - val_loss: 0.4020 - val_accuracy: 0.8150\n",
      "Epoch 343/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1719 - accuracy: 0.9275 - val_loss: 0.4418 - val_accuracy: 0.8050\n",
      "Epoch 344/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1725 - accuracy: 0.9321 - val_loss: 0.3797 - val_accuracy: 0.8333\n",
      "Epoch 345/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2263 - accuracy: 0.8954 - val_loss: 0.4205 - val_accuracy: 0.8200\n",
      "Epoch 346/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2681 - accuracy: 0.8750 - val_loss: 0.3674 - val_accuracy: 0.8050\n",
      "Epoch 347/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2460 - accuracy: 0.8942 - val_loss: 0.3718 - val_accuracy: 0.8200\n",
      "Epoch 348/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2167 - accuracy: 0.9046 - val_loss: 0.4859 - val_accuracy: 0.7750\n",
      "Epoch 349/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2121 - accuracy: 0.9083 - val_loss: 0.3519 - val_accuracy: 0.8300\n",
      "Epoch 350/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2015 - accuracy: 0.9200 - val_loss: 0.5105 - val_accuracy: 0.7633\n",
      "Epoch 351/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1901 - accuracy: 0.9242 - val_loss: 0.3576 - val_accuracy: 0.8517\n",
      "Epoch 352/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2190 - accuracy: 0.8975 - val_loss: 0.3874 - val_accuracy: 0.8050\n",
      "Epoch 353/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1801 - accuracy: 0.9308 - val_loss: 0.4429 - val_accuracy: 0.7933\n",
      "Epoch 354/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1999 - accuracy: 0.9121 - val_loss: 0.3827 - val_accuracy: 0.8133\n",
      "Epoch 355/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1765 - accuracy: 0.9300 - val_loss: 0.3777 - val_accuracy: 0.8250\n",
      "Epoch 356/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1826 - accuracy: 0.9242 - val_loss: 0.3812 - val_accuracy: 0.8200\n",
      "Epoch 357/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1780 - accuracy: 0.9275 - val_loss: 0.4056 - val_accuracy: 0.8283\n",
      "Epoch 358/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1750 - accuracy: 0.9246 - val_loss: 0.4250 - val_accuracy: 0.8067\n",
      "Epoch 359/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1749 - accuracy: 0.9254 - val_loss: 0.4006 - val_accuracy: 0.8233\n",
      "Epoch 360/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1689 - accuracy: 0.9342 - val_loss: 0.4969 - val_accuracy: 0.7683\n",
      "Epoch 361/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1875 - accuracy: 0.9196 - val_loss: 0.6308 - val_accuracy: 0.7117\n",
      "Epoch 362/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2292 - accuracy: 0.8950 - val_loss: 0.3748 - val_accuracy: 0.8633\n",
      "Epoch 363/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2866 - accuracy: 0.8625 - val_loss: 0.5263 - val_accuracy: 0.7450\n",
      "Epoch 364/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2646 - accuracy: 0.8758 - val_loss: 0.3988 - val_accuracy: 0.8200\n",
      "Epoch 365/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1946 - accuracy: 0.9196 - val_loss: 0.3707 - val_accuracy: 0.8217\n",
      "Epoch 366/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1856 - accuracy: 0.9250 - val_loss: 0.6969 - val_accuracy: 0.6900\n",
      "Epoch 367/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2339 - accuracy: 0.8975 - val_loss: 0.3744 - val_accuracy: 0.8700\n",
      "Epoch 368/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2301 - accuracy: 0.9025 - val_loss: 0.5439 - val_accuracy: 0.7517\n",
      "Epoch 369/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1820 - accuracy: 0.9275 - val_loss: 0.3572 - val_accuracy: 0.8367\n",
      "Epoch 370/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1815 - accuracy: 0.9254 - val_loss: 0.4034 - val_accuracy: 0.8283\n",
      "Epoch 371/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2400 - accuracy: 0.8879 - val_loss: 0.5428 - val_accuracy: 0.7433\n",
      "Epoch 372/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2245 - accuracy: 0.8975 - val_loss: 0.3751 - val_accuracy: 0.8683\n",
      "Epoch 373/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2230 - accuracy: 0.8992 - val_loss: 0.4597 - val_accuracy: 0.7833\n",
      "Epoch 374/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2172 - accuracy: 0.9046 - val_loss: 0.4252 - val_accuracy: 0.8200\n",
      "Epoch 375/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2013 - accuracy: 0.9175 - val_loss: 0.3563 - val_accuracy: 0.8317\n",
      "Epoch 376/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1792 - accuracy: 0.9242 - val_loss: 0.5369 - val_accuracy: 0.7533\n",
      "Epoch 377/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1889 - accuracy: 0.9250 - val_loss: 0.3688 - val_accuracy: 0.8417\n",
      "Epoch 378/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1984 - accuracy: 0.9112 - val_loss: 0.3945 - val_accuracy: 0.8133\n",
      "Epoch 379/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2534 - accuracy: 0.8804 - val_loss: 0.7265 - val_accuracy: 0.6917\n",
      "Epoch 380/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2795 - accuracy: 0.8733 - val_loss: 0.3773 - val_accuracy: 0.8700\n",
      "Epoch 381/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2333 - accuracy: 0.8963 - val_loss: 0.4711 - val_accuracy: 0.7833\n",
      "Epoch 382/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1978 - accuracy: 0.9196 - val_loss: 0.3718 - val_accuracy: 0.8217\n",
      "Epoch 383/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1873 - accuracy: 0.9192 - val_loss: 0.4073 - val_accuracy: 0.8117\n",
      "Epoch 384/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2170 - accuracy: 0.9042 - val_loss: 0.4206 - val_accuracy: 0.8233\n",
      "Epoch 385/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2098 - accuracy: 0.9112 - val_loss: 0.3597 - val_accuracy: 0.8167\n",
      "Epoch 386/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1765 - accuracy: 0.9275 - val_loss: 0.4079 - val_accuracy: 0.8250\n",
      "Epoch 387/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1842 - accuracy: 0.9229 - val_loss: 0.3976 - val_accuracy: 0.8233\n",
      "Epoch 388/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1636 - accuracy: 0.9375 - val_loss: 0.4491 - val_accuracy: 0.8017\n",
      "Epoch 389/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1714 - accuracy: 0.9329 - val_loss: 0.3997 - val_accuracy: 0.8167\n",
      "Epoch 390/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1954 - accuracy: 0.9100 - val_loss: 0.6200 - val_accuracy: 0.7283\n",
      "Epoch 391/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2119 - accuracy: 0.9067 - val_loss: 0.3619 - val_accuracy: 0.8683\n",
      "Epoch 392/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1854 - accuracy: 0.9171 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "Epoch 393/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1902 - accuracy: 0.9187 - val_loss: 0.3614 - val_accuracy: 0.8583\n",
      "Epoch 394/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2708 - accuracy: 0.8771 - val_loss: 0.5760 - val_accuracy: 0.7450\n",
      "Epoch 395/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1934 - accuracy: 0.9208 - val_loss: 0.3683 - val_accuracy: 0.8467\n",
      "Epoch 396/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2511 - accuracy: 0.8850 - val_loss: 0.3953 - val_accuracy: 0.8100\n",
      "Epoch 397/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2199 - accuracy: 0.9013 - val_loss: 0.4331 - val_accuracy: 0.8017\n",
      "Epoch 398/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2242 - accuracy: 0.8988 - val_loss: 0.3918 - val_accuracy: 0.8667\n",
      "Epoch 399/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2594 - accuracy: 0.8771 - val_loss: 0.5918 - val_accuracy: 0.7267\n",
      "Epoch 400/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2130 - accuracy: 0.9083 - val_loss: 0.3775 - val_accuracy: 0.8617\n",
      "Epoch 401/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2431 - accuracy: 0.8933 - val_loss: 0.4290 - val_accuracy: 0.8200\n",
      "Epoch 402/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2248 - accuracy: 0.9004 - val_loss: 0.4110 - val_accuracy: 0.8150\n",
      "Epoch 403/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1901 - accuracy: 0.9179 - val_loss: 0.4126 - val_accuracy: 0.8283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1721 - accuracy: 0.9296 - val_loss: 0.4582 - val_accuracy: 0.7983\n",
      "Epoch 405/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1694 - accuracy: 0.9362 - val_loss: 0.3633 - val_accuracy: 0.8133\n",
      "Epoch 406/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1647 - accuracy: 0.9350 - val_loss: 0.3804 - val_accuracy: 0.8200\n",
      "Epoch 407/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1688 - accuracy: 0.9312 - val_loss: 0.3722 - val_accuracy: 0.8200\n",
      "Epoch 408/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1552 - accuracy: 0.9421 - val_loss: 0.3827 - val_accuracy: 0.8067\n",
      "Epoch 409/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1625 - accuracy: 0.9321 - val_loss: 0.4697 - val_accuracy: 0.7917\n",
      "Epoch 410/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1692 - accuracy: 0.9279 - val_loss: 0.3560 - val_accuracy: 0.8283\n",
      "Epoch 411/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1650 - accuracy: 0.9312 - val_loss: 0.5470 - val_accuracy: 0.7600\n",
      "Epoch 412/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1727 - accuracy: 0.9250 - val_loss: 0.3707 - val_accuracy: 0.8267\n",
      "Epoch 413/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1611 - accuracy: 0.9388 - val_loss: 0.3984 - val_accuracy: 0.8283\n",
      "Epoch 414/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1637 - accuracy: 0.9337 - val_loss: 0.4433 - val_accuracy: 0.8100\n",
      "Epoch 415/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1799 - accuracy: 0.9208 - val_loss: 0.3700 - val_accuracy: 0.8367\n",
      "Epoch 416/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2109 - accuracy: 0.9062 - val_loss: 0.4345 - val_accuracy: 0.7933\n",
      "Epoch 417/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2532 - accuracy: 0.8829 - val_loss: 0.4793 - val_accuracy: 0.7717\n",
      "Epoch 418/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1986 - accuracy: 0.9146 - val_loss: 0.3703 - val_accuracy: 0.8450\n",
      "Epoch 419/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1824 - accuracy: 0.9183 - val_loss: 0.7063 - val_accuracy: 0.7050\n",
      "Epoch 420/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1924 - accuracy: 0.9192 - val_loss: 0.3671 - val_accuracy: 0.8450\n",
      "Epoch 421/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1845 - accuracy: 0.9262 - val_loss: 0.7381 - val_accuracy: 0.6950\n",
      "Epoch 422/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2133 - accuracy: 0.9054 - val_loss: 0.3761 - val_accuracy: 0.8533\n",
      "Epoch 423/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2145 - accuracy: 0.9050 - val_loss: 0.6153 - val_accuracy: 0.7417\n",
      "Epoch 424/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1929 - accuracy: 0.9175 - val_loss: 0.3689 - val_accuracy: 0.8250\n",
      "Epoch 425/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1685 - accuracy: 0.9292 - val_loss: 0.4118 - val_accuracy: 0.8233\n",
      "Epoch 426/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1645 - accuracy: 0.9362 - val_loss: 0.3819 - val_accuracy: 0.8133\n",
      "Epoch 427/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1637 - accuracy: 0.9342 - val_loss: 0.3816 - val_accuracy: 0.8200\n",
      "Epoch 428/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1768 - accuracy: 0.9258 - val_loss: 0.4969 - val_accuracy: 0.7800\n",
      "Epoch 429/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1710 - accuracy: 0.9304 - val_loss: 0.3749 - val_accuracy: 0.8367\n",
      "Epoch 430/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1674 - accuracy: 0.9267 - val_loss: 0.4249 - val_accuracy: 0.8217\n",
      "Epoch 431/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1796 - accuracy: 0.9250 - val_loss: 0.6293 - val_accuracy: 0.7267\n",
      "Epoch 432/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2222 - accuracy: 0.8983 - val_loss: 0.3865 - val_accuracy: 0.8600\n",
      "Epoch 433/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1738 - accuracy: 0.9237 - val_loss: 0.4549 - val_accuracy: 0.7917\n",
      "Epoch 434/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1843 - accuracy: 0.9229 - val_loss: 0.3856 - val_accuracy: 0.8667\n",
      "Epoch 435/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2144 - accuracy: 0.9029 - val_loss: 0.5331 - val_accuracy: 0.7667\n",
      "Epoch 436/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2120 - accuracy: 0.9075 - val_loss: 0.3870 - val_accuracy: 0.8000\n",
      "Epoch 437/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1814 - accuracy: 0.9217 - val_loss: 0.3770 - val_accuracy: 0.8100\n",
      "Epoch 438/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1580 - accuracy: 0.9375 - val_loss: 0.4966 - val_accuracy: 0.7817\n",
      "Epoch 439/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1530 - accuracy: 0.9388 - val_loss: 0.3695 - val_accuracy: 0.8450\n",
      "Epoch 440/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1539 - accuracy: 0.9354 - val_loss: 0.5138 - val_accuracy: 0.7750\n",
      "Epoch 441/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1623 - accuracy: 0.9312 - val_loss: 0.3853 - val_accuracy: 0.8100\n",
      "Epoch 442/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1538 - accuracy: 0.9383 - val_loss: 0.4435 - val_accuracy: 0.8133\n",
      "Epoch 443/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1713 - accuracy: 0.9233 - val_loss: 0.6989 - val_accuracy: 0.7100\n",
      "Epoch 444/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1930 - accuracy: 0.9167 - val_loss: 0.3675 - val_accuracy: 0.8317\n",
      "Epoch 445/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1564 - accuracy: 0.9325 - val_loss: 0.3930 - val_accuracy: 0.8233\n",
      "Epoch 446/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1491 - accuracy: 0.9421 - val_loss: 0.4402 - val_accuracy: 0.8117\n",
      "Epoch 447/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1514 - accuracy: 0.9404 - val_loss: 0.3729 - val_accuracy: 0.8233\n",
      "Epoch 448/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1586 - accuracy: 0.9371 - val_loss: 0.3793 - val_accuracy: 0.8383\n",
      "Epoch 449/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1958 - accuracy: 0.9137 - val_loss: 0.4120 - val_accuracy: 0.8183\n",
      "Epoch 450/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2069 - accuracy: 0.9087 - val_loss: 0.6363 - val_accuracy: 0.7300\n",
      "Epoch 451/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2246 - accuracy: 0.9000 - val_loss: 0.3624 - val_accuracy: 0.8217\n",
      "Epoch 452/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1962 - accuracy: 0.9192 - val_loss: 0.5373 - val_accuracy: 0.7700\n",
      "Epoch 453/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1817 - accuracy: 0.9221 - val_loss: 0.3978 - val_accuracy: 0.8667\n",
      "Epoch 454/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1950 - accuracy: 0.9187 - val_loss: 0.6821 - val_accuracy: 0.7267\n",
      "Epoch 455/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2174 - accuracy: 0.9121 - val_loss: 0.3762 - val_accuracy: 0.8667\n",
      "Epoch 456/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2572 - accuracy: 0.8813 - val_loss: 0.5507 - val_accuracy: 0.7550\n",
      "Epoch 457/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3102 - accuracy: 0.8554 - val_loss: 0.3416 - val_accuracy: 0.8683\n",
      "Epoch 458/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3051 - accuracy: 0.8637 - val_loss: 0.7221 - val_accuracy: 0.6783\n",
      "Epoch 459/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2893 - accuracy: 0.8758 - val_loss: 0.5195 - val_accuracy: 0.8283\n",
      "Epoch 460/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3677 - accuracy: 0.8267 - val_loss: 0.6881 - val_accuracy: 0.6683\n",
      "Epoch 461/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3129 - accuracy: 0.8554 - val_loss: 0.3607 - val_accuracy: 0.8683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2561 - accuracy: 0.8925 - val_loss: 0.5622 - val_accuracy: 0.7233\n",
      "Epoch 463/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2589 - accuracy: 0.8921 - val_loss: 0.3540 - val_accuracy: 0.8100\n",
      "Epoch 464/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2451 - accuracy: 0.8904 - val_loss: 0.4878 - val_accuracy: 0.7633\n",
      "Epoch 465/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1970 - accuracy: 0.9183 - val_loss: 0.3724 - val_accuracy: 0.8150\n",
      "Epoch 466/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1869 - accuracy: 0.9225 - val_loss: 0.4047 - val_accuracy: 0.8033\n",
      "Epoch 467/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1815 - accuracy: 0.9267 - val_loss: 0.4997 - val_accuracy: 0.7683\n",
      "Epoch 468/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1923 - accuracy: 0.9250 - val_loss: 0.3589 - val_accuracy: 0.8233\n",
      "Epoch 469/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1874 - accuracy: 0.9237 - val_loss: 0.3881 - val_accuracy: 0.8017\n",
      "Epoch 470/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1847 - accuracy: 0.9225 - val_loss: 0.3776 - val_accuracy: 0.8067\n",
      "Epoch 471/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1812 - accuracy: 0.9296 - val_loss: 0.4179 - val_accuracy: 0.8067\n",
      "Epoch 472/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1924 - accuracy: 0.9212 - val_loss: 0.3683 - val_accuracy: 0.8383\n",
      "Epoch 473/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1985 - accuracy: 0.9229 - val_loss: 0.3642 - val_accuracy: 0.8150\n",
      "Epoch 474/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1875 - accuracy: 0.9212 - val_loss: 0.4917 - val_accuracy: 0.7667\n",
      "Epoch 475/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2404 - accuracy: 0.8900 - val_loss: 0.3888 - val_accuracy: 0.8067\n",
      "Epoch 476/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1854 - accuracy: 0.9271 - val_loss: 0.3930 - val_accuracy: 0.8000\n",
      "Epoch 477/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1752 - accuracy: 0.9333 - val_loss: 0.3985 - val_accuracy: 0.8033\n",
      "Epoch 478/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1899 - accuracy: 0.9171 - val_loss: 0.5251 - val_accuracy: 0.7533\n",
      "Epoch 479/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1933 - accuracy: 0.9183 - val_loss: 0.3599 - val_accuracy: 0.8233\n",
      "Epoch 480/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1868 - accuracy: 0.9283 - val_loss: 0.4471 - val_accuracy: 0.7983\n",
      "Epoch 481/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1943 - accuracy: 0.9150 - val_loss: 0.5673 - val_accuracy: 0.7367\n",
      "Epoch 482/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2211 - accuracy: 0.9000 - val_loss: 0.3611 - val_accuracy: 0.8233\n",
      "Epoch 483/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2070 - accuracy: 0.9046 - val_loss: 0.5572 - val_accuracy: 0.7400\n",
      "Epoch 484/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2393 - accuracy: 0.8883 - val_loss: 0.4981 - val_accuracy: 0.7683\n",
      "Epoch 485/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2025 - accuracy: 0.9133 - val_loss: 0.3776 - val_accuracy: 0.8450\n",
      "Epoch 486/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1958 - accuracy: 0.9058 - val_loss: 0.5699 - val_accuracy: 0.7367\n",
      "Epoch 487/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2193 - accuracy: 0.9079 - val_loss: 0.4012 - val_accuracy: 0.8700\n",
      "Epoch 488/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2616 - accuracy: 0.8842 - val_loss: 0.5602 - val_accuracy: 0.7417\n",
      "Epoch 489/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2047 - accuracy: 0.9108 - val_loss: 0.3553 - val_accuracy: 0.8600\n",
      "Epoch 490/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2375 - accuracy: 0.8896 - val_loss: 0.5982 - val_accuracy: 0.7317\n",
      "Epoch 491/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2118 - accuracy: 0.9092 - val_loss: 0.3844 - val_accuracy: 0.8633\n",
      "Epoch 492/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2676 - accuracy: 0.8838 - val_loss: 0.4613 - val_accuracy: 0.7783\n",
      "Epoch 493/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2044 - accuracy: 0.9129 - val_loss: 0.3736 - val_accuracy: 0.8183\n",
      "Epoch 494/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2025 - accuracy: 0.9171 - val_loss: 0.3861 - val_accuracy: 0.8017\n",
      "Epoch 495/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1873 - accuracy: 0.9225 - val_loss: 0.4150 - val_accuracy: 0.8033\n",
      "Epoch 496/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1843 - accuracy: 0.9237 - val_loss: 0.3749 - val_accuracy: 0.8100\n",
      "Epoch 497/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1794 - accuracy: 0.9287 - val_loss: 0.4085 - val_accuracy: 0.8033\n",
      "Epoch 498/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2251 - accuracy: 0.8992 - val_loss: 0.3893 - val_accuracy: 0.8033\n",
      "Epoch 499/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3061 - accuracy: 0.8642 - val_loss: 0.3482 - val_accuracy: 0.8250\n",
      "Epoch 500/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2603 - accuracy: 0.8921 - val_loss: 0.5560 - val_accuracy: 0.7433\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8240\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#In this training we implement the same methodology as in the paper by using early stopping and a maximum of 500 iterations. \n",
    "train_log = MLP.fit(X, Y, epochs=500, batch_size=n_steps, verbose=1, validation_split=0.2,\n",
    "        callbacks=[EarlyStopping(monitor='accuracy', min_delta=1e-8, restore_best_weights=True, patience=100)])\n",
    "\n",
    "#We use now the X_val and Y_val to evaluate the quality of the training. \n",
    "val_acc = MLP.evaluate(X_val, Y_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We achieved 82.40000009536743 % accuracy on Validation and  94.20833587646484 % accuracy on Training\n"
     ]
    }
   ],
   "source": [
    "print(\"We achieved\", val_acc[1]*100, \"% accuracy on Validation and \", max(train_log.history[\"accuracy\"])*100, \"% accuracy on Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "The previous training has generated a record of the training, test and validation accuracy as well as the evolution of the loss throughout the epochs. \n",
    "\n",
    "These can be plotted to see how the model is learning the outcome. To do this we need to callback the history which is in \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss  = train_log.history[\"loss\"]\n",
    "val_loss = train_log.history[\"val_loss\"]\n",
    "acc_train = train_log.history[\"accuracy\"]\n",
    "acc_val = train_log.history[\"val_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,3))\n",
    "ax[0].plot(np.array(acc_train)*100, color=\"r\", label=\"Training accuracy\")\n",
    "ax[0].plot(np.array(acc_val)*100, color=\"g\", label=\"Validation accuracy\")\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax[1].plot(loss, label=\"training loss\", color=\"r\")\n",
    "ax[1].plot(val_loss, label=\"validation loss\", color=\"g\")\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"loss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can move onto trying the MLTSA for this ML model. For that we call the MLTSA() method within the tensorflow package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLTSA__(data, ans, model, mode=\"\"):\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    if mode == \"Normal\":\n",
    "        data = data[:, :-1, :]\n",
    "\n",
    "    # Calculating the global means\n",
    "    means_per_sim = np.mean(data.T, axis=0)\n",
    "    gmeans = np.mean(means_per_sim, axis=1)\n",
    "    temp_sim_data = np.copy(data)\n",
    "\n",
    "    # Swapping the values and predicting for the FR\n",
    "    FR = []\n",
    "    for y, data in tqdm(enumerate(temp_sim_data)):\n",
    "        mean_sim = []\n",
    "        for n, mean in enumerate(gmeans):\n",
    "            tmp_dat = np.copy(data)\n",
    "            # print(tmp_dat.shape)\n",
    "            tmp_dat[n, :] = mean\n",
    "            # print(tmp_dat.T.shape)\n",
    "            yy = model.predict(tmp_dat.T)\n",
    "            res = yy == ans[y]\n",
    "            mean_sim.append(res)\n",
    "        FR.append(mean_sim)\n",
    "    print()\n",
    "    fr_per_sim = np.mean(np.array(FR).T, axis=0)\n",
    "    fr = np.mean(fr_per_sim, axis=1)\n",
    "    return fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [10:24,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#from MLTSA_tensorflow.MLTSA_tf import MLTSA\n",
    "\n",
    "ans_labels = encoder.fit_transform(np.array(ans).reshape(-1,1)).toarray()\n",
    "\n",
    "a_drop = MLTSA__(data[:,:,time_frame[0]:time_frame[1]], ans_labels, MLP, mode=\"tf\")\n",
    "\n",
    "#MLTSA__(data[:10,:,0:10], ans_labels[:10], MLP, mode=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
